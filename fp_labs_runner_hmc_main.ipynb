{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# **FloodProofs Labs - HMC Runner** \n",
    "\n",
    "<img style=\"float: left; padding-right: 80px; padding-left: 5px;\" src=\"img/logo_hmc.png\" width=\"200px\" align=”left” >\n",
    "\n",
    "In the laboratory of **HMC runner** we will perform the following points:\n",
    "   * Configure the libraries and the dependecies of the laboratory;\n",
    "   * Read the configuration file of the laboratory;\n",
    "   * Read the static datasets of terrain, river networks and outlet sections;\n",
    "   * Read the dynamic datasets of the time-series (collections and hydrographs);\n",
    "   * Plot the position of the analyzed outlet section;\n",
    "   * Plot the time-series of discharge and the time-series of the hmc average forcings.    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Import libraries and dependencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ==> Library HMC /home/fabio/fp_labs_hmc/library/jupyter_hmc/ added to the library environments\n"
     ]
    }
   ],
   "source": [
    "# Add hmc library to the paths environment\n",
    "import sys\n",
    "import os\n",
    "\n",
    "folder_home_env = os.path.expanduser('~')\n",
    "folder_library_hmc = \"/fp_labs_hmc/library/jupyter_hmc/\"\n",
    "\n",
    "folder_library_hmc = folder_home_env + folder_library_hmc\n",
    "sys.path.append(folder_library_hmc)\n",
    "\n",
    "print(' ==> Library HMC ' + folder_library_hmc + ' added to the library environments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ==> Libraries loaded\n"
     ]
    }
   ],
   "source": [
    "# Libraries\n",
    "import argparse\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# Import method to adapt settings file\n",
    "from library.jupyter_generic.lib_jupyter_utils_io import update_json_file\n",
    "\n",
    "# Import coupler and driver classes\n",
    "from hmc.driver.configuration.drv_configuration_hmc_logging import ModelLogging\n",
    "from hmc.coupler.cpl_hmc_manager import ModelInitializer, ModelCleaner\n",
    "from hmc.coupler.cpl_hmc_builder import ModelBuilder\n",
    "from hmc.coupler.cpl_hmc_runner import ModelRunner\n",
    "from hmc.coupler.cpl_hmc_finalizer import ModelFinalizer\n",
    "\n",
    "# Info\n",
    "print(' ==> Libraries loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Configure the HMC runner laboratory**\n",
    "- Set the notebook arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the algorithm and datasets configuration file(s)\n",
    "script_settings_algorithm_default=\"fp_labs_runner_hmc_algorithm_default.json\"\n",
    "script_settings_algorithm_defined=\"fp_labs_runner_hmc_algorithm_defined.json\"\n",
    "script_settings_datasets_default=\"fp_labs_runner_hmc_datasets_default.json\"\n",
    "script_settings_datasets_defined=\"fp_labs_runner_hmc_datasets_defined.json\"\n",
    "# Define the time \n",
    "script_time='2021-01-21 06:00'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Update the configuration file(s) according with the environment variable(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the script time as a timestamp object\n",
    "script_time = pd.Timestamp(script_time)\n",
    "\n",
    "# Set environment variables to json settings file(s)\n",
    "update_json_file(script_settings_algorithm_default, script_settings_algorithm_defined,\n",
    "                 update_dict={'$ENV_HOME': folder_home_env, '$ENV_TIME': script_time.strftime(\"%Y%m%d_%H\")})\n",
    "update_json_file(script_settings_datasets_default, script_settings_datasets_defined,\n",
    "                 update_dict={'$ENV_HOME': folder_home_env, '$ENV_TIME': script_time.strftime(\"%Y%m%d_%H\")})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Initialize the instance of HMC model**\n",
    "- Set the logging file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set logging file\n",
    "driver_hmc_logging = ModelLogging(script_settings_algorithm_defined)\n",
    "log_stream = driver_hmc_logging.configure_logging()\n",
    "\n",
    "# Set the verbose debug level\n",
    "log_stream.setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Configure the initializer model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the verbose debug level\n",
    "log_stream.setLevel(logging.ERROR)\n",
    "\n",
    "# Configure model initializer class\n",
    "driver_hmc_initializer = ModelInitializer(file_algorithm=script_settings_algorithm_defined,\n",
    "                                          file_datasets=script_settings_datasets_defined, time=script_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configure the algorithm and the ancillary datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure algorithm\n",
    "time_series_collections, time_info_collections, \\\n",
    "    run_info_collections, run_cline_collections = driver_hmc_initializer.configure_algorithm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure ancillary datasets\n",
    "ancillary_datasets_collections = driver_hmc_initializer.configure_ancillary_datasets(time_info_collections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Build the instance of HMC model**\n",
    "- Configure the builder model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the verbose debug level\n",
    "log_stream.setLevel(logging.ERROR)\n",
    "\n",
    "# Configure model builder class\n",
    "driver_hmc_builder = ModelBuilder(\n",
    "    obj_geo_reference=driver_hmc_initializer.dset_ref_geo,\n",
    "    obj_args=driver_hmc_initializer.obj_args,\n",
    "    obj_run=driver_hmc_initializer.obj_run,\n",
    "    obj_ancillary=driver_hmc_initializer.obj_ancillary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configure the static and the dynamic datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-25 15:49:17,372 hmc_logger   ERROR     ===> File static /home/fabio/fp_labs_datasets/data_static/shapefile/fp_sections_marche.shp is mandatory! Execution exit. drv_dataset_hmc_io_type.py:[200    - read_filename_static()] \n",
      "2021-01-25 15:49:17,372 hmc_logger   ERROR     ===> File static /home/fabio/fp_labs_datasets/data_static/shapefile/fp_sections_marche.shp is mandatory! Execution exit. drv_dataset_hmc_io_type.py:[200    - read_filename_static()] \n",
      "2021-01-25 15:49:17,372 hmc_logger   ERROR     ===> File static /home/fabio/fp_labs_datasets/data_static/shapefile/fp_sections_marche.shp is mandatory! Execution exit. drv_dataset_hmc_io_type.py:[200    - read_filename_static()] \n",
      "2021-01-25 15:49:17,372 hmc_logger   ERROR     ===> File static /home/fabio/fp_labs_datasets/data_static/shapefile/fp_sections_marche.shp is mandatory! Execution exit. drv_dataset_hmc_io_type.py:[200    - read_filename_static()] \n",
      "2021-01-25 15:49:17,372 hmc_logger   ERROR     ===> File static /home/fabio/fp_labs_datasets/data_static/shapefile/fp_sections_marche.shp is mandatory! Execution exit. drv_dataset_hmc_io_type.py:[200    - read_filename_static()] \n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "File not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-bfaf6d622749>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Configure static datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mstatic_datasets_collections\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdriver_hmc_builder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfigure_static_datasets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mancillary_datasets_collections\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/fp_labs_hmc/library/jupyter_hmc/hmc/coupler/cpl_hmc_builder.py\u001b[0m in \u001b[0;36mconfigure_static_datasets\u001b[0;34m(self, ancillary_datasets_collections, ancillary_tag_type)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;31m# Method to analyze and collect static datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0mstatic_datasets_collections\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdriver_io_source\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalyze_data_static\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatic_datasets_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;31m# Method to write static datasets collections\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fp_labs_hmc/library/jupyter_hmc/hmc/driver/dataset/drv_dataset_hmc_base_source.py\u001b[0m in \u001b[0;36manalyze_data_static\u001b[0;34m(self, obj_static_datasets, tag_datatype, tag_datadriver)\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0mdset_source_subset_static\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj_static_datasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfile_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             dset_source_frame_raw = reader_dataset.collect_data(dset_source_subset_static,\n\u001b[0;32m--> 152\u001b[0;31m                                                                 data_source_static=var_data_dict)\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdset_source_frame_merge\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fp_labs_hmc/library/jupyter_hmc/hmc/driver/dataset/drv_dataset_hmc_io_static.py\u001b[0m in \u001b[0;36mcollect_data\u001b[0;34m(self, dset_source_static, data_source_static)\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvar_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m                 \u001b[0mdriver_hmc_parser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDSetReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_src_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m                 \u001b[0mobj_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdriver_hmc_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_filename_static\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mvar_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m                 \u001b[0mdriver_hmc_parser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDSetWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_dst_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fp_labs_hmc/library/jupyter_hmc/hmc/driver/dataset/drv_dataset_hmc_io_type.py\u001b[0m in \u001b[0;36mread_filename_static\u001b[0;34m(self, var_name)\u001b[0m\n\u001b[1;32m    200\u001b[0m                 \u001b[0mlog_stream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' ===> File static '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' is mandatory! Execution exit.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0mlog_stream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' ------> Read variable '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mvar_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' ... FAILED'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'File not found'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m                 \u001b[0mlog_stream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' ===> File static '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' is ancillary! Execution continue.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: File not found"
     ]
    }
   ],
   "source": [
    "# Configure static datasets\n",
    "static_datasets_collections = driver_hmc_builder.configure_static_datasets(ancillary_datasets_collections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure dynamic datasets\n",
    "forcing_datasets_collections = driver_hmc_builder.configure_dynamic_datasets(\n",
    "    time_series_collections, time_info_collections, static_datasets_collections, ancillary_datasets_collections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Run the instance of HMC model**\n",
    "- Configure the runner model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the verbose debug level\n",
    "log_stream.setLevel(logging.ERROR)\n",
    "\n",
    "# Configure model runner class\n",
    "driver_hmc_runner = ModelRunner(time_info=time_info_collections, run_info=run_info_collections,\n",
    "                                command_line_info=run_cline_collections,\n",
    "                                obj_args=driver_hmc_initializer.obj_args,\n",
    "                                obj_ancillary=driver_hmc_initializer.obj_ancillary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Execute the instance of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the model execution\n",
    "driver_hmc_runner.configure_execution(ancillary_datasets_collections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Finalize the instance of the model**\n",
    "- Configure the finalizer class of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure model finalizer class\n",
    "driver_hmc_finalizer = ModelFinalizer(\n",
    "    collection_dynamic=forcing_datasets_collections,\n",
    "    obj_geo_reference=driver_hmc_initializer.dset_ref_geo,\n",
    "    obj_args=driver_hmc_initializer.obj_args,\n",
    "    obj_run=driver_hmc_initializer.obj_run,\n",
    "    obj_ancillary=driver_hmc_initializer.obj_ancillary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dump the model results in gridded, point and time-series format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the outcome datasets\n",
    "outcome_datasets_collections = driver_hmc_finalizer.configure_dynamic_datasets(\n",
    "    time_series_collections, time_info_collections, static_datasets_collections, ancillary_datasets_collections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dump the model results in collections format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the summary datasets\n",
    "driver_hmc_finalizer.configure_summary_datasets(\n",
    "    time_series_collections, time_info_collections, static_datasets_collections, outcome_datasets_collections)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
